# Data Engineer
Portfolio
#### Technical Skills: Python, SQL, Azure, GCP, Hadoop, Apache Spark, Apache Airflow, Elasticsearch

## Education
- M.Eng., ECE | Ontario Tech University (2022)								       		
- B.Tech., ECE  | SRM Institute of Science & Tech (2018)

## Work Experience
**Data Engineer @ Scotiabank (_June 2023 - Present_)**
- Implemented an in-house PySpark-based framework to consolidate data from various sources, utilizing Parquet for data ingestion and historical data conversion, resulting in a 30% reduction in storage costs within 9 months.
- Conducted strategic ETL pipeline data migration, enhancing performance by 20% through rigorous post-conversion testing and ad-hoc troubleshooting of data type mismatches and encoding issues, ensuring the efficient weekly transfer of ~4 TB of data.
- Maximized data integration accuracy by 95% through optimized marker files and COBOL copybooks, aligning data with evolving business requirements.
Collaborated with cross-functional teams to manage project life cycle using JIRA ensuring adherence to project timelines and reducing issue resolution time by 15% through JIRA.
- Produced comprehensive dataset documentation and metadata, facilitating ease of understanding and utilization by stakeholders, resulting in a 15% decrease in data-related errors and issues, amounting to annual savings of $40K in operational costs.
- Gathered and analysed business and functional requirements, translating them into robust, scalable solutions aligned with organizational data architecture.

**Systems Engineer @ Infosys(Client - Pfizer) (_August 2018 - June 2020_)** 
- Improved report generation time by 75%, from 4 days to <1 day by developing automated bi-weekly Power BI dashboards, allowing for faster data-driven decisions.
- Implemented data ingestion routines, encompassing both real-time and batch processes, adhering to best practices in data modelling. Achieved a reduction in data ingestion latency by 30% through optimization techniques.
- Engineered efficient SQL pipelines to analyse 1500 web application logs, resulting in a 12% reduction in recurring errors within 6 months for a leading US pharmaceutical company.
- Developed ETL processes leveraging Azure technologies and Big Data tools, resulting in a 40% decrease in data processing time, translating to annual savings of $80K in infrastructure costs.
- Optimized 20+ batch processes using Python scripts, resulting in an 8% increase in ticket volume and decreased maintenance requirements.
- Streamlined and shared 50+ data processes, reducing high-priority ticket resolution time by over 20% and optimizing access control.
- Produced comprehensive and user-friendly dataset documentation and metadata to facilitate seamless data management and understanding.




